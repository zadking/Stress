import pandas as pd
import csv
import numpy as np
from scipy import stats
from sklearn.cluster import KMeans,AgglomerativeClustering,Birch,MiniBatchKMeans,SpectralClustering
from sklearn.svm import SVC
from collections import Counter
from sklearn.metrics import f1_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split

def findlabel(part,act,data,definitions):
    index = 0
    for val in data:
        if val[0] == part:
            if val[1] in act:
                return definitions[index]
        index += 1
    print [part,act]


ttest = pd.read_csv('ttestfeaturedata.csv')
act = ttest['activity']
index =0
TSST = []
Rest = []
features = []
for val in act:
    if 'Arithmetic' in val or 'Speech' in val:
        TSST.append(index)
    if 'rest' in val:
        Rest.append(index)
    index += 1
for col in ttest:
    if 'Participant' in col or 'activity' in col or 'window_number' in col:
        continue
    else:
        x = ttest[col].iloc[TSST]
        y = ttest[col].iloc[Rest]
        stat, p =  stats.ttest_ind(list(x),list(y))
        if p < .05:
            features.append(col)
ecgfeatures = [x for x in features if 'ecg' in x]
gsrfeatures = [x for x in features if 'neulog' in x]
ecggsrfeatures = ecgfeatures + gsrfeatures
df = pd.read_csv('definition.csv')
dm = df[['part','activity']]
da = dm.as_matrix()
df = df[['yesNo','average','pss','consensus']]
part_label = list(ttest['Participant'])
act_label = list(ttest['activity'])
for i in range(0,3):
    
    if i == 0:
        name = 'ecg'
        cluster = ecgfeatures
    elif i == 1:
        name = 'gsr'
        cluster = gsrfeatures
    elif i == 2:
        name = 'ecg+gsr'
        cluster = ecggsrfeatures
    with open(name+'generalized.csv','w') as csvfile:
        write = csv.writer(csvfile,delimiter= ',')
        for col in df:
            definitions = list(df[col])
            deflabelmin = []
            for i in range(len(ttest.as_matrix())):
                deflabelmin.append(findlabel(part_label[i],act_label[i],da,definitions))
            labels = pd.DataFrame(data = deflabelmin, columns = ['Label'])
            totaldata = pd.concat([ttest,labels], axis = 1)
            with open(name+'personalized.csv','w') as csvfile:
                for p in np.unique(part_label):
                    testtotal = totaldata.loc[totaldata['Participant'] == p]
                    testdata = testtotal[cluster].as_matrix()
                    testlabel = testtotal['Label'].as_matrix()
                    ptestdata = testtotal[cluster].as_matrix()
                    ptestlabel = testtotal['Label'].as_matrix()
                    X_train, X_test, y_train, y_test = train_test_split(
                        ptestdata, ptestlabel, test_size=20,  groups = testtotal['activity'].as_matrix())
                    print [len(X_train),len(X_test)]
                    traintotal = totaldata.loc[totaldata['Participant'] != p]
                    traindata = traintotal[cluster].as_matrix()
                    trainlabel = traintotal['Label'].as_matrix()
                    clf = GaussianNB()
                    
                    clf.fit(traindata,trainlabel)
                    predicted = clf.predict(testdata)
                    write.writerow([name,p,col,f1_score(testlabel,predicted)])
       
                          
    
